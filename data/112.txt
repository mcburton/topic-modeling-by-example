A few months ago, Science published a Thanksgiving article on what scientists can be grateful for. It’s got a lot of good points, like being thankful for family members who accept the crazy hours we work, or for those really useful research projects that make science cool enough for us to get funding for the merely really interesting. It does have one unfortunate reference to humanists:
We are thankful that Ph.D. programs in the sciences, as much as we complain about them, aren’t nearly as horrifying as, say, Ph.D. programs in the humanities. I just heard today from a friend in his ninth year of a comparative literature Ph.D. who thinks he might finish “in a year and a half.” At least the job market for comp lit Ph.D. awardees is thriving, right?
Ouch. I suppose the truth hurts. The particularly interesting point that inspired this post, however, was:
We are thankful for that one colleague who knows statistics. There’s always one.
A Scientist's Thanksgiving. (Image from the above Science article)
The above quote about statisticians is so true it hurts, as (we just discovered) the truth is wont to do. It’s even more true in the humanities than it is in the more natural and quantitative sciences. When we talk about a colleague who knows statistics, we generally don’t mean someone down the hall; usually, we mean that one statistician who we met in the pub that one night and has a bizarre interest in the humanities. That’s not to say humanist statisticians don’t exist, but I doubt you’re likely to find one in any given humanities department.
This unfortunately is not only true of statistics, but also of GIS, network science, computer science, textual analysis, and many other disciplines we digital humanists love to borrow from. Thankfully, the NEH ODH’s Institutes for Advanced Topics in the Humanities, UVic’s Digital Humanities Summer Institutes, and other programs out there are improving our collective expertise, but a quick look for GIS/Stats/SNA/etc. courses in most humanities departments still produces slim pickings.
Math is scary. (I can't find attribution, sorry. Anybody know who drew this?)
One of the best things to come out of the #hacker movement in the Digital Humanities has been the spirit to get our collective hands dirty and learn the techniques ourselves. It’s been a long time coming, and happier days are sure to follow, but one skill still seems underrepresented from the DH purview: statistics.
In a recent post by Elijah Meeks, he called Text Analysis, Spatial Analysis, and Network Analysis the “three pillars” of DH research, with a sneaking suspicion that Image Analysis should fit somewhere in there as well. This seems to be the converging sentiment in most DH circles, and although when asked most would say statistics is also important, it still doesn’t seem to be among the first subjects named.
With another round of Digging Into Data winners chosen, and a bevy of panels and presentations dedicating themselves to Big Data in the Humanities, the first direction we should point is statistics. Statistics is a tool uniquely built for understanding lots of data, and it was developed with full knowledge that the data may be incomplete, biased, or otherwise imperfect, and has legitimate work-arounds for most such occasions. Of course, all the caveats in my first Networks Demystified post apply here: don’t use it without fully understanding it, and changing it where necessary.
http://vadlo.com/cartoons.php?id=71
Many Humanists, even digital ones, frequently seem to have a (justifiably) knee-jerk reaction to statistics. If you’ve been following the Twitter and blog conversations about AHA 2012, you probably caught a flurry of discussion over Google Ngrams. Conversation tended toward horrified screams of the dangers of correlation vs. causation (or at least references to xkcd), and the ease with which one might lie via statistics or omission. These are all valid cautions, especially where ngrams is concerned, but I sometimes fear we get so caught up in bad examples that we spend more time apologizing for them than fixing them. Ted Underwood has a great post about just this, which I will touch on again shortly. (And, to Ted and Allen specifically, I’m guessing you both will enjoy this post.)
In short: statistics is useful. To quote the above-linked xkcd comic:
Correlation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’.
So how do we go about using statistics? In a comment on Ted’s recent post about statistics, Trevor Owens wrote:
if you just start signing up for statistics courses you are going to end up getting a rundown on using t-tests and ANOVAs as tools for hypothesis testing. The entire hypothesis testing idea remains a core part of how a lot of folks in the social sciences think about things and it is deeply at odds with what humanists want to do.
The key is not appropriation but adaption. We must learn statistics, even the hypothesis testing, so that we might find what methods are useful, what might be changed, and how we can get it to work for us. We’re humanists. We’re really good at methodological critique.
One of the areas of statistics most likely to bear fruit for humanists is Bayesian statistics. Some of us already use it in our text mining algorithms, although the math involved remains occult to most. It basically builds uncertainty and belief directly into statistics. Instead of coming up with one correct answer, Bayesian analysis often yields a range of more or less probable answers depending what seems to be the case from prior evidence, and can update and improve that range as more is learned.
The one XKCD comic nobody seems to have linked to. (http://xkcd.com/892/)
For humanists, this importance is (at least) two-fold. Ted Underwood sums up the first reason nicely:
[Bayesian inference] is amazingly, almost bizarrely willing to incorporate subjective belief into its definition of knowledge. It insists that definitions of probability have to depend not only on observed evidence, but on the “prior probabilities” that we expected before we saw the evidence. If humanists were more familiar with Bayesian statistics, I think it would blow a lot of minds.
The second and more specific reason worth mentioning here deals with the ranges I discussed above. If a historian, for example, is trying to understand how and why some historical event happened, Bayesian analysis could yield which set of occurrences were more or less likely, and which were so far off as to not be worth considering. By trying to find reasonable boundary conditions rather than exact explanations to answer our questions, humanists can retain that core knowledge that humans and human situations are not wholly deterministic machines, who all act the same and reproduce the same results in every situation.
We are intrinsically and inextricably inexact, and until we get computers that see and remember everything, and model it all perfectly, we should avoid looking for exact answers. Bayesian statistics, instead, can help us find a range of reasonable answers, with full awareness and use of the beliefs and evidence we have going in.
After I read that post about a scientist’s thanksgiving, I realized I didn’t want to have to rely on that one colleague who knows statistics. Nobody should. That’s why I decided to enroll in a Bayesian Data Analysis course this semester, taught by and using the book of John K. Kruschke. It’s a very readable book, directed toward people with no prior knowledge in statistics or programming, and takes you through the basics of both. Kruschke’s got a blog worth reading, as does Andrew Gelman, an author of the book Bayesian Data Analysis. I’m sure a basic Google search can point you to video lectures, if that’s your thing. I’ll also try to blog about it over the coming months as I learn more.
There are several (occasionally apocryphal) anecdotes about the great theoretical physicists of the early 20th century needing to go back to school to learn basic statistics. Some still weren’t terribly happy about it (“God does not play dice with the universe”), but in the end, pressures from the changing nature of their theories required a thorough understanding of statistics. As humanists begin to deal with a glut of information we never before had access to, it’s time we adapt in a similar fashion.
The wide angle, the distant reading, the longue durée will all benefit from a deeper understanding of statistics. That knowledge, in tandem with traditional close reading skills, will surely become one of the pillars of humanities research as Big Data becomes ever-more common.
 
Welcome to the scottbot irregular. My name’s Scott, and the US Government has for some reason seen fit to give me money to study Science. It’s ‘Science’ with a capital ‘S’ because I’m not studying individual aspects of the world using science, but rather studying Science in general as a social, historical, philosophical, and intellectual phenomenon. What’s worse, I’m attempting to do it scientifically. This blog is my attempt at giving the country its money’s worth. Also, I kinda would love feedback on my eventual dissertation. See? Everybody wins.
scott b. weingart
is pretty clueless about a lot of things. This is his attempt to be less so.
I pledge to be a good scholarly citizen. This includes:
Opening all data generated by me for the purpose of a publication at the time of publication.
Opening all code generated by me for the purpose of a publication at the time of publication.
Freely distributing all published material for which I have the right, and fighting to retain those rights in situations where that is not the case.
Fighting for open access of all materials worked on as a co-author, participant in a grant, or consultant on a project.
I pledge to support open access by:
Only reviewing for journals which plan to release their publications openly.
Donating to free open source software initiatives where I would otherwise have paid for proprietary software.
Citing open publications if there is a choice between two otherwise equivalent sources.
I pledge never to let work get in the way of play.
I pledge to give people chocolate occasionally if I think they’re awesome.
_
[This is somewhat out of date. Please stand by for new information!]
Hello World!
Student of History & Philosophy of Science and Information Science at Indiana University.
You’ve managed to stumble across my little corner of the internet. I’m currently a student and researcher in the HPS and SLIS departments at IUB under two of the most interesting and capable professors I’ve had the fortune to meet: Colin Allen and Katy Börner. I studied history of science and computer engineering at UF, where I slaved researched for the infinitely patient Robert A. Hatch, who taught me more in four short years than I’d yet learned in aggregate over my entire life.
Early InPhO Concept Map
These days, I split my time between classes, the Indiana Philosophy Ontology Project (InPhO) and the Cyberinfrastructure for Network Science Center (CNS). At InPhO I program and design visual, navigable representations of our dynamically generated taxonomy of ideas; analyze relational networks (influenced, disagreed with, etc.) from our Thinkers database; and map and compare philosophical ontologies. The CNS keeps me busy with all sorts of scientometric analyses, and I am also involved in the development of large scale network analysis software such as the NWB, creating workflows, providing software feedback, writing documentation and teaching workshops.
Co-authorship network created using the Network Workbench Tool
Research
How do changes in communication structures and technologies affect scientific discourse and collaboration?
Science is totally rad. So I study it.
There are all sorts of ways to study science, of course, and you can’t leave out even one if you want to understand Science as a whole. That means taking a look at its philosophy, history, anthropology, culture and all sorts of other things as well (perhaps even sociology!). It also means looking at (gasp) the science itself, because no self-respecting scholar should claim to understand physics and physicists without being able to calculate the distance the bullet travels before it falls.
My overarching research is in modeling and mapping the growth of science on a large scale – thematically, geographically and temporally – hoping eventually to reveal what conditions yield the most rapid rate of discovery and innovation. Looking back, we see times when scientific progress lurches forward at alarming rates, times when studies come to a halt, times when great minds exposit to deaf ears. Sometimes the reasons are obvious: burned libraries, overthrown empires, new sources of funding, technological breakthroughs, wars that need to be won. But these are heavy brush-strokes painted across the canvas of history.
If we could somehow view the whole of scientific endeavors for the last thousand years, across every topic and in every city, with the same fine granularity used to research modern-day science, imagine how much we could learn. By zooming out and looking for “hot spots” of innovation in the history of science, and by understanding the environment in which these hot spots formed, we can learn how to induce those same ideal conditions in modern day research.
If the synthesis of new ideas in physics tends to come from young researchers working on their own and with backgrounds in other fields, funds can be allotted to make sure more of those exist. If medical innovations come fastest when small groups of experts collaborate, or if science in general runs smoother in small-world type collaborative networks rather than completely connected networks, that information can be used to focus funding in just the right way to improve the rate of innovation.
The closest we can come to that fine granularity, to understanding science across contexts, is by using as many research tools as we can find. We must be comfortable working in whatever discipline with whatever methodology is necessary to find the answers sought. Huge historical data sets will be a must. Scientometricians and others in related fields do an amazing job of learning the structure of modern science, but that structure is necessarily bound to the mediums it inhabits. Modern science is a beast of national laboratories, e-mails, universities, cited journals, click-throughs, conferences and page hits.
Marshall McLuhan may or may not have been correct when he claimed “the medium is the message,” but there is no doubt that the medium plays a large role in how science is adopted, disseminated and studied. That role cannot be understood without stepping back and viewing all of the alternatives – correspondences, scientific societies, book transcriptions, etc.
Dutch Republic of Letters created in collaboration with The Huygens Instituut
The task, then, is to collect as much data as possible, as far back as we can. We should track where books traveled within Medieval Europe and Asia; who corresponded with whom, how often, and about what during the Early Modern period; who taught whom and where scientists studied; how many books were published in what languages; what universities had copies of which journals; where shared resources traveled.
This is an impossible amount of data, of course, and can only exist if created collaboratively and in the spirit of openness. These are not ideas to be copyrighted – they are numbers and data points, and they should be accessible and compatible and aggregated in one place. A History of Science Data Commons, so to speak. More on that project coming soon.
Trying to understand all of it at once is a big task… and absolutely impossible.  I’ve sliced myself two pieces of the pie that are hopefully manageable and definitely inseparable:
Periods of rapid scientific production and progress.
Inflection points in scientific communication and collaboration.
Changes in communication structures and technologies obviously affect scientific progress deeply, and it is exactly what those effects are that I hope to uncover. Scientific revolutions and media revolutions, what a tired subject! Well, perhaps, but there are two very good reasons they’re overstudied: they’re terribly important, and nobody’s got them right yet.
Interests
Courtney and I contact juggling
Thankfully for my friends and family I do not work 24/7. When not working, I can often be found juggling, attending renaissance festivals, geocaching, camping, campaigning for rationality, and reading science fiction & fantasy novels. When I feel guilty about not working, but not enough to actually get back to work, I read about physics, cognitive science and linguistics. I am also perpetually writing a history of the obscure art of contact juggling.
Juggling has been a big part of my life for nearly a decade now; I was president of Objects in Motion (UF Juggling Club) for a few years and brought the club from 3 to 30 active members, taught lessons at Groovolution dance studio, and performed with Circle & Spice in Bloomington. I’m now involved in the IU Juggling Club and juggle irregularly at the Bloomington Farmer’s Market. I have performed as far north as Calgary, as far east as Amsterdam, as far west as Los Angeles, all the way south in Miami, and all sorts of places in between.
None of that would have been possible without my good friends and co-performers in the Spherocity contact juggling troupe: Matt, Jay, Cory, Courtney, Steve, and Leighanna. Thanks to Nick, Nicole, Leah, Ian and the rest of the crew, Objects in Motion keeps growing larger and better and I miss them terribly. And if you’re reading this, Sierra, you should start juggling again.
Juggling knives in Calgary
As if there’s not enough on my plate already, I’m also involved in two wonderful pseudo-academic organizations. I co-founded Sophosessions with Warren C. Moore, the coolest cat I know, in my junior year at UF. The group still meets a little more than monthly and allows its two-dozen members to present talks on whatever they feel like, from Chinese calligraphy to Zen Buddhism to advanced fractal mathematics to building robots. Then everyone goes to Ben & Jerry’s. I still webcast into meetings whenever I can, but it’s just not the same without the ice-cream.
The Venerable IU Beer & Algorithms Club fills two Monday nights a month, and I get to listen to a bunch of Computer Science and Math graduates present their favorite algorithms in gory detail, all while eating a tasty meal and enjoying an equally tasty beverage. What could be better?